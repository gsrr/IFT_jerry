
<h1 class="sectionedit1" id="section20190826">20190826</h1>
<div class="level1">
<pre class="file">1. ULINLK Project
    - Discussion with &quot;Total number of bays of each NAS model&quot;
        - The PCIe information is not necessary due to the PCIe drive is viewed as a expansion device.
        - Provide Mein with template data to confirm it.
    - Error handle mechanism (4.5.0 done, 4.4.x Wait for PM notification)

2. V2188
    - Marvell driver and AQC driver can work normally.
    - Summary the procedure in Jira.

3. Smart migration (4.5.0 done)
    - Collect test report for Jira task.

4. SAS trim functionality.
([Bug 226215] [Samsung MZILT960HAHQ][TVS-EC1680U-SAS] SSD的資訊顯示不支援 SSD Trim功能)
關於這個問題, 要先確認一下有哪些cases需要處理...
從code看起來, 入口點都統一是在pd_sys_getinfo,
看起來應該只要處理getinfo_pd_in_root_boot_enclosure 與 getinfo_pd_in_sas_expander
</pre>

</div>
<!-- EDIT1 SECTION "20190826" [1-875] -->
<h1 class="sectionedit2" id="section20190819">20190819</h1>
<div class="level1">
<pre class="file">1. ULINK Project:
    - sata template index error. (Done)
    - raid info template format error. (Done)

2. Others
    - [Bug 226031] [TS-2088XU] 開關機Reboot測試時,發生開機過程中卡住的情形(call trace)
    (It may be the memory HW issue, take over by Citizen)
    
    - jira (SIRT-7) Create a basic ubuntu 18.04 driver collection list for VIS-2888 ()
        - Marvell Code compile (In progress)
        - AQC code compile (Done)
        - Marvell driver test (In progress)
        - 10G port test (In progress)

    - [Bug 226215] [Samsung MZILT960HAHQ][TVS-EC1680U-SAS] SSD的資訊顯示不支援 SSD Trim功能
        - SCSI trim function study (Done)
            - Logical Block Provisioning VPD page (B2H)
            - PD_CAP_TRIM -- (B0H and B2H) and (LBPU or LBPWS or LBPWS10)
            - PD_CAP_DZAT -- LBPRZ
        - HAL Code study and implementation (In progress)

toDo:
    - ULINK, merge &quot;error handle mechanism&quot; to QTS_4.4.x and QTS_4.4.1
    - [Bug 226215] [Samsung MZILT960HAHQ][TVS-EC1680U-SAS] SSD的資訊顯示不支援 SSD Trim功能
    - jira (SIRT-7) Create a basic ubuntu 18.04 driver collection list for VIS-2888 ()
    - Discussion with &quot;Total number of bays of each NAS model&quot;
    - Systemtrap test in QTS image.

Pending:
    - Raid info template enhancement (wait for jira number from PM and Jmicro).
    - SATA/SAS enhancement (wait for jira number from PM)
    - API for communicating with ULINK (wait for jira number from PM)

</pre>

</div>
<!-- EDIT2 SECTION "20190819" [876-2398] -->
<h1 class="sectionedit3" id="section20190812">20190812</h1>
<div class="level1">
<pre class="file">[Summary]
1. SSD life estimation in smart disk migration
    - Functionality implementation --&gt; Done.
    - Event notification --&gt; Wail for PM

2. ULINK
    - Ignore QDA disk --&gt; Done
    - io-test integration with Storage-man API --&gt; Done
    - da_util log mechanism --&gt; Done
    - Fix Nvme self test log analysis --&gt; In progress

3. [Bug 226031] [TS-2088XU] 開關機Reboot測試時,發生開機過程中卡住的情形(call trace)
    - Null pointer error in kernfs_put
    - Null pointer error in kernfs_iop_permission

4. ToDo
    - [Bug 226031] Analysis
    - Raid info template enhancement (wait for jira number from PM and Jmicro).
    - SATA/SAS enhancement (wait for jira number from PM)
    - API for communicating with ULINK (wait for jira number from PM)
    - Systemtrap test in QTS image.

- [Bug 226031] [TS-2088XU] 開關機Reboot測試時,發生開機過程中卡住的情形(call trace)
稍微看了一下, 從code trace可以發現:
1. 總共有兩次的開關機.
2. Bug是發生在第二次的關機.
3. unable to handle kernel NULL pointer. (在kernfs_put這個function)
   而這個function是由__kernfs_remove所觸發.
4. oops 為0000, 表示:
bit 0 == 0 means no page found, 1 means a protection fault
bit 1 == 0 means read, 1 means write
bit 2 == 0 means kernel, 1 means user-mode

* IP is the instruction pointer.
* RIP is the CPU register containing the address of the instruction that is getting executed.
* my_oops_init+0x12/0x21 is the &lt;symbol&gt; + the offset/length.
--&gt; The first number is offset from the beginning of the function.
--&gt; The second number is total length of the function.

Reference: (Analysis Kernel dump trace)
1. https://stackoverflow.com/questions/13468286/how-to-read-understand-analyze-and-debug-a-linux-kernel-panic
2. https://opensourceforu.com/2011/01/understanding-a-kernel-oops/
3. https://www.freebsd.org/doc/en/books/developers-handbook/kerneldebug.html

看起來似乎會有race condition的狀況, 如果同時有兩個人進來, 只是奇怪, 這居然沒有處理好.
如果同時有兩個人進到atomic_dec_and_test:
if (!kn || !atomic_dec_and_test(&amp;kn-&gt;count))
    return;

這時第一個人先離開, 並且free掉了, 然後第二個人正準備要進去atomic_dec_and_test,
他去取出kn-&gt;count, 就會造成Null pointer的問題.

kernfs_remove_by_name_ns --&gt; __kernfs_remove


</pre>

</div>
<!-- EDIT3 SECTION "20190812" [2399-4792] -->
<h1 class="sectionedit4" id="section20190805">20190805</h1>
<div class="level1">
<pre class="file">[Summary]
1. ULINK project
    - Ignore TR disk --&gt; Done.
    - Serial number missing in NVMe drive--&gt; Done
    - file lock mechanism for SATA error cnt --&gt; Done
    - Bug 226039 - [Disk Analysis] Apply the setting of &quot;Share my disk analysis data with QNAP&quot;，show error message . (Done)
    - Confirm with lack of &quot;Rack number&quot; and &quot;Slot number&quot; --&gt; Done

2. SSD life estimation in smart disk migration
    - Function for getting ssd life percentage --&gt; testing...
    - Event message enhancement --&gt; in progress

3. ToDo
    - Ignore QDA disk
    - Raid info template enhancement (wait for jira number from PM and Jmicro).
    - SATA/SAS enhancement (wait for jira number from PM)
    - API for communicating with ULINK (wait for jira number from PM)
    - Systemtrap test in QTS image. 
    - da_util log mechanism

4. Personal
    - 將centos 上的git repo移到ubuntu
    - 將post-commit 與re_exec_patch連接起來

[20190802]
幾個事項大概都已經完成了:
1. Ignore TR disk.
2. file lock
3. Serial number problem of NVMe

另外就是遇到Ulink回報問題: lack of &quot;No. of Records&quot;, &quot;Rack number&quot; and &quot;Slot number&quot;
最後是缺乏&quot;Rack number&quot; and &quot;Slot number&quot;的部分是Ulink的test data.

現在要準備處理smart disk migration, 應該今天可以完成.
還有Raid info template --&gt; 需要修改structure.
SATA/SAS Template enhancement要等PM開Jira task.
還有剛剛Josphe 新增template control的功能.(定義好了, 但是要怎麼透過api溝通?)
QDA這個裝置也需要濾掉.


</pre>

</div>
<!-- EDIT4 SECTION "20190805" [4793-6349] -->
<h1 class="sectionedit5" id="section20190729">20190729</h1>
<div class="level1">
<pre class="file">[Summary]
1. ULINK Project 
    - Merge SATA and SAS template into QTS 4.4.1 --&gt; Done
    - Error handle mechanism for fail to upload. --&gt; Testing...
      - Bug of cloud upload tool. --&gt; Done
    - SAS and NVMe header data error --&gt; Done
      - Add gen_header function in da_util. 
      - Modify header mechanism for SATA, SAS, NVMe
      (Bug 141364 - [Disk Failure Analysis][NVMe]disk data collection and upload to QNAP cloud 資料需要匿名收集)
    - Latency count enhancement --&gt; Done.

2. Smart migration(add SSD life time for consideration) --&gt; In progress
    - Work flow of smart migration --&gt; Done
    - Event discussion with PM --&gt; Done

3. ToDo
    - TR disk test for ULNK project
    - file lock for read/write statistic data.
    - Systemtrap test in QTS image. 
    - Raid info template enhancement.
    - SATA/SAS Template enhancement
    - Fetch serial number in NVMe

Q: How to implement module_init mechanism in C?
Ans:

Q: usb disk如何回報變成一個scsi disk?

[20190723]
目前已經將code merge到branch 4.4.x了.
雖然ULINK的部分還是有些bug (像換行問題, 與hash問題)
但目前可能要先花時間確認一下smart disk migration的功能

[Smart Disk Migration]
Q4 : smart health predict會回傳一個smart id, 這個smart id的用意是?
Ans:
smart id如果是SATA的話會回傳abnormal的smart項目 id.
如果是SAS的話只會回傳-1
Nvme則會回傳0 (不做事情)

Q3 : 從文件看起來並不是透過polling, 是由一個HW monitor來通知, 這個monitor是...?
Ans:
靠, 是/sbin/hal_daemon ...
(static void *hal_hd_smart_monitor(void *thread_name))

目前看起來polling時間是6分鐘,  
(disk_smart_time = smart_interval_mins * 60;)
hal_hd_smart_monitor(7149):DISK S.M.A.R.T interval = 300 seconds


Q2 : 監控每一顆disk?
Ans:
看起來是要監控每一顆disk沒錯, 掃描過所有的enclosure與其中的所有disk.
每一個disk 都呼叫 SDM_device(dev_id)來進行處理.
那...
1. 在SDM_device裡面, 是抓取smart data來進行判斷嗎?然後抓取Raid info, 
然後抓取Raid info, 看看有沒有spare drive.
若從smart data得知disk快壞掉的話, 且是Raid5, spare drive也存在, 就進行migration?

Q1 : What is smart disk migration?
Ans : 
就是會自動判斷disk的狀態來進行migration.
一點疑問就是...
1. 所以要監控每一顆disk? (抓取smart data)
2. 從文件看起來並不是透過polling, 是由一個HW monitor來通知, 這個monitor是...?</pre>

</div>
<!-- EDIT5 SECTION "20190729" [6350-8858] -->
<h1 class="sectionedit6" id="section20190722">20190722</h1>
<div class="level1">
<pre class="file">1. ULINK Project 
    - Raid info template for SATA, SAS, Nvme --&gt; Done.
    - Latency count improvement(Both Kernel and hal_util) --&gt; Done.
        * Add a variable in scsi_cmnd to record jiffies.
        * Add transfer size for calculating latency.
        * Modify latency time to 300ms(SSD), 1000ms + (transfer_size/256)*2ms(HDD)
    - SAS template 334 --&gt; Done.

2. Smart migration(add SSD life time for consideration) --&gt; In progress
    - NasUtil/sdmd/sdmd.c

3. ToDo
    - Merge SATA and SAS template into QTS 4.4.1
    - TR disk test for ULNK project
    - Error handle mechanism for fail to upload.
    - file lock for read/write statistic data.
    - Systemtrap test in QTS image. 

[   31.142795] BUG: unable to handle kernel paging request at ffff88019c8d4780
[   31.149754] IP: 0xffff88019c8d4780
[   31.153148] PGD 28cb067 P4D 28cb067 PUD 28ce067 PMD 19d3d4063 PTE 800000019c8d4063
[   31.160712] Oops: 0011 [#1] SMP PTI
[   31.164195] Modules linked in: qm2_i2c(O) intel_ips drbd lru_cache flashcache(O) dm_tier_hro_algo dm_thin_pool dm_bio_prison dm_persistent_data hal_netlink(O) k10temp coretemp igb e1000e nvme(O) nvme_core(O) mlx_compat(O) mpt3sas scsi_transport_sas raid_class scsi_transport_fc usb_storage xhci_pci xhci_hcd usblp uhci_hcd ehci_pci ehci_hcd


Reference: https://blog.csdn.net/han_dawei/article/details/41846055

--&gt; 這個問題在整個image進行重build後就解決了, 所以應該只是有些東西沒有build到, 造成kernel在refer memory時位置不正確?

* 目前已經把sas template 334 (standard inquiry data)實作完成了.
但是昨天透過repo clean, repo sync的方式要進行重新編譯會一直fail...?
(先試著把整個資料夾刪掉再build一次看看)

* latency 對於transfer length的部分要implement.
* SAS template跟SATA template要merge到QTS4.4.1
* 上傳data的error handle要處理(fail時要存起來)
* file lock



</pre>

</div>
<!-- EDIT6 SECTION "20190722" [8859-10799] -->
<h1 class="sectionedit7" id="section20190715">20190715</h1>
<div class="level1">
<pre class="file">1. ULINK project:
    1. Raid info template implementation --&gt; In progress (testing...)
        1.1 Integrate with storage-man --&gt; Done.
        1.2 Solve bug in Nvme segment(No. of Records and memory issue) --&gt; Done.
        1.3 Ignore template 16, 201, 202 if default volume doesn&#039;t exist. --&gt; Done.
        1.4 Adjust code flow and add Raidinfo into sata, sas, nvme data. --&gt; Done.
        
    2. API for deleting all statistic data --&gt; Done.
    3. Confirm latency count equation with ULINK --&gt; Done.
    
2. Set up Build server --&gt; Done.

3. ToDo:
    1. file lock for read/write statistic data.
    2. Latency count in SCSI layer implementation.
    3. Systemtrap test in QTS image. 
    4. Error handle mechanism for fail to upload.
    5. SAS template --&gt; standard inquiry data</pre>

</div>
<!-- EDIT7 SECTION "20190715" [10800-11626] -->
<h1 class="sectionedit8" id="section20190708">20190708</h1>
<div class="level1">
<pre class="file">[Summary]
1. AWS EBS volume performace test - Done, the result is summarized in jira.
(https://qnap-jira.qnap.com.tw/browse/CLDVCLD0-12)

2. Multipath in device mapper with Nvme
    - Group priority setting : No suitable hw parameter for Nvme.
    - Group id for identifying : Extended Unique Identifier(EUI64)

3. ULINK project:
    - Raid info template structure define ---&gt; Done.
    - Update SAS template (Add template 333 and modify template 332) ---&gt; Done
        * Add config mechanism for adjusting length dynamically.
    - Enable / Disable mechanism in hal layer. --&gt; Done
    - API for deleting all files. --&gt; In progress
    
4. Set up Build server environment --&gt; In progress.

ToDo:
    1. file lock for read/write statistic data.
    2. Raid info template implementation
    3. Latency count in SCSI layer implementation.
    4. Systemtrap test in QTS image.   
    
目前手頭上交代的事情都弄得差不多了...

現在需要處理的應該是把一些ULINK要修改的部分處理完成.
1. Define Raid info template for storage-man
  --&gt; 確認有無jira number?
2. Implement latency count in SCSI layer.
3. file lock for read/write statistic data.
4. API for deleting all files
5. Systemtrap test in QTS image.

Personal:
Implementation phrase:
1. 在自己的local git上進行修改, 改完後更新到build server進行編譯.
2. build server編譯完後, 將檔案更新到NAS, 進行驗證.
  - 這裡是不是應該要有個test script來進行測試.
  - 更新到NAS的動作可以自動化, 而且最好是可以編譯完-&gt;上傳到NAS-&gt;重開機-&gt;開完機後執行test script-&gt;顯示結果.

Alpha test phrase:
1. 建立新資料夾, 從repo下載最新的檔案.
2. 進入docker, 建立相關檔案.
3. 選擇model, 開始編譯
4. 將image更新到NAS, 重開機後進行驗證測試.



Attention:
1. 在branch回歸之前不可以pull, 否則會被remote server洗掉tag.

==================================================================
1. vQTS驗證
目前一開始接收到的訊息是要進行io performance(對五種aws所提供的volume)
從機器看, volume已經建好, 分別是:
1. /dev/sdb --&gt; /dev/xvdb (274.8GB) --&gt; general purpose SSD (gp2)
2. /dev/sdc --&gt; /dev/xvdc (309.2GB) --&gt; Provisioned IOPS SSD (io1) 
3. /dev/sdd --&gt; /dev/xvdd (549.7GB) --&gt; Cold HDD (sc1)
4. /dev/sde --&gt; /dev/xvde (584.1GB) --&gt; Throughtput optimized HDD (st1)
5. /dev/sdf --&gt; /dev/xvdf (343.5GB) --&gt; Magnetic (standard)

馬的, 複雜... 我總要先知道它們測試的基準是甚麼, 不然測出來的數據要怎麼比較?
gp2/io1 --&gt; 16 KiB I/O size
st1/sc1 --&gt; 1 MiB I/O size

AWS EBS--&gt; 稱為AWS Elastic Block Store, 是Amazon提供的區塊儲存區.
這個block device主要分為兩種類型:
1. 大量交易的工作 --&gt; 效能取決於IOPS, 適用SSD支援儲存. (io1 &amp; gp2)
2. 輸送輛密集型的工作 --&gt; 效能取決於每秒的MB, 適用於HDD支援儲存. (st1 &amp; sc1)

所以io1 &amp; gp2是使用16K IO大小來進行測試, 而st1 &amp; sc1是使用1MB IO大小.


test command of AWS:
[iops]
fio --name=/dev/xvdc --direct=1 --rw=read --bs=16k --size=1G --numjobs=64 --time_based --runtime=10 --iodepth=64

[throughput]
fio --name=/dev/xvde --direct=1 --rw=write --randrepeat=0 --bs=1024k --time_based=1 --runtime=20 --iodepth=8


[Reference]
1. banchmark
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/benchmark_procedures.html

----AWS Summary ----
IOPS : The request number of IO operations per second.

gp2 調整到1000GB的原因: 3 IOPS per GB, 所以3000 IOPS為 1000GB

[Command]
1. io1 &amp; gp2
sudo fio --name=/dev/xvdb  --direct=1 --rw=randread --bs=16k --size=1G --numjobs=16 --time_based --runtime=30  --norandommap --group_reporting

2. st1 &amp; sc1
sudo fio --name=/dev/xvde --direct=1 --rw=write --randrepeat=0 --bs=1024k --time_based=1 --runtime=30 --iodepth=8 --size=100G --ioengine=libaio

[Test Result]
ubuntu(sc1) --&gt; write:     io=1900.0MB, bw=64593KB/s, iops=63, runt= 30121msec
ubuntu(st1) --&gt; write:     io=1900.0MB, bw=64584KB/s, iops=63, runt= 30125msec
ubuntu(gp2) --&gt; randwrite: io=1482.4MB, bw=50588KB/s, iops=3161, runt= 30006msec
ubuntu(io1) --&gt; randwrite: io=1892.6MB, bw=64590KB/s, iops=4036, runt= 30004msec

qts(sc1) --&gt; write: 	 io=1899.0MB, bw=64570KB/s, iops=63, runt= 30116msec
qts(st1) --&gt; write:      io=1899.0MB, bw=64574KB/s, iops=63, runt= 30114msec
qts(gp2) --&gt; randwrite:  io=759280KB, bw=25308KB/s, iops=1581, runt= 30001msec
qts(io1) --&gt; randwrite:  io=634048KB, bw=21134KB/s, iops=1320, runt= 30001msec
qts(magnetic) --&gt; write: io=1842.0MB, bw=62602KB/s, iops=61, runt= 30130msec


[Reference]
1. benchmark
https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/benchmark_procedures.html

2. Amazon EBS Volume Type
https://docs.aws.amazon.com/en_us/AWSEC2/latest/UserGuide/EBSVolumeTypes.html</pre>

</div>
<!-- EDIT8 SECTION "20190708" [11627-16461] -->
<h1 class="sectionedit9" id="section20190701">20190701</h1>
<div class="level1">
<pre class="file">1. Enable/Disable mechanism.
    1.1 確認可以從User space發event下去.
    1.2 想寫一個外部程式來測試hal的netlink function.
    
2. multipath功能確認, 目前的QTS(linux 4.14是否有support?)
    2.1 目前已經架好環境(ubuntu with linux 4.14), 搭配Nvme測試後可以正常建立multipath of devmapper.
    2.2 接下來就是進行io test.
    2.3 另外好奇的一點是... Nvme在multipath是bio-based or request-based?
    (照理說應該不是request-based, 這部分應該可以使用ftrace來進行確認.)
    2.4 進行測試: failover and failback 與資料正確性 (fio可以檢查?).
    
4. 補充test report for sas template --&gt; Done

ToDo:
1. io test program by python.
2. ubuntu - ssh with root login
3. multipath fio test error test (failover/failover in fio test)


整個netlink覺得怪怪的, 感覺不應該送不下去, 到底kernel有沒有跑起來阿?
機車, 又不太好確定.
只是奇怪的一點, 為什麼從userspace送下去的msg不用指定msghdr指定dst_addr (包含port id)?
Ans:
終於確定了, 原來netlink宣告的一些structure需要放在global area, 之前一直放在local area才會導致一直fail.
不過怎麼會這樣呢? 後面可能需要確認一下.
--&gt; 原來不是這麼一回事, 是因為:
&quot;it&#039;s on the stack, the memory for it isn&#039;t zeroed and you have garbage in some field.&quot;

- 檢查hal_netlink : lsmod|grep hal_netlink

不過今天大概要處理的事項是:
1. 將ulink enable/disable 的機制完成.
2. build linux 4.14, 為了trace multipath.
(還是先用4.18來看?)

============================================================
1. Ulink project:
    - Enable / Disable mechanism in Kernel. --&gt; Done
    - Confirm latency setting with ULINK. --&gt; In progress
    - Raid template implementation --&gt; In progress.

2. Multipath in devmapper 
    2.1 Confirm multipath function with Nvme in QTS image --&gt; Done
        (multipath-tool - 0.4.9 &amp; linux 4.14)
    2.2 Confirm multipath function with Nvme in ubuntu environment. --&gt; Done
        (multipath-tool - 0.7.4 &amp; linux 4.14)
        - Performance Evaluation (&quot;multibus&quot;, &quot;failover&quot;, and &quot;no-multipath&quot;)
        - Failover / Failback test
        - Verify error handle function during failover/failback.
    
3. ToDo
    3.1. Raid template info implementation

    3.2. ULINK Enhancement:
        - adjust latency time implementation.
        - file lock for statistic data file.
        - API for deleting all files.
 
    3.3 Systemtap in QTS image
</pre>

</div>
<!-- EDIT9 SECTION "20190701" [16462-19013] -->
<h1 class="sectionedit10" id="section20190624">20190624</h1>
<div class="level1">
<pre class="file">1. Ulink project:
    - SAS template implementation --&gt; Done.
    - Change the file location and add check function for default volume. --&gt; Done
    - Latency event issue in booting phase --&gt; Done
      (The latency time will be adjust : HDD (100ms to 1000ms), SSD (10ms to 300ms))
    - Enable / Disable mechanism in Kernel. --&gt; In progress

2. ToDo
    2.1. Multipath for Nvme.

    2.2. ULINK Enhancement:
        - file lock for statistic data file.
        - API for deleting all files.
 
    2.3 Systemtap in QTS image

====================================
1. Personal
    - documentation for Lecroy ()
    - syntastic for c language  --&gt; Done. 
用vim plugin中的syntastic來進行檢查, 會有兩個checker, 一個是cppcheck, 一個是gcc

    - development environment setting

2. Ulink project
    - Change the file location. --&gt; Done
  大概已經ok了 , 測試過後行為上符合預期.
  
    - SAS template implementation
    - SATA error count enable/disable

Q1: How to send hal event from user space?
NETLINK_EVT event;
if (UTIL_Test_PD_Flag(pd, DISK_IN_STANDBY))
    UTIL_Debug(TRACE_INFO, &quot;%s(%d):PD still in standby mode,enc_id = %d,port_id = %d\n&quot;,__func__, __LINE__, enc-&gt;enc_id, pd-&gt;port_id);
    event.type = HAL_EVENT_GENERAL_DISK;
    event.arg.action = SET_PD_STANDBY;
    event.arg.param.netlink_pd.enc_id = enc-&gt;enc_id;
    memcpy(event.arg.param.netlink_pd.scsi_bus, pd-&gt;scsi_bus, sizeof(pd-&gt;scsi_bus));
    EVT_Send_To_Kernel(netlink_hd_fd, &amp;event);

Q2: hal receive event是在nasdriver裡面, 這裡要如何獨立去build出這個module?
Ans:
</pre>

</div>
<!-- EDIT10 SECTION "20190624" [19014-20637] -->
<h1 class="sectionedit11" id="section20190617">20190617</h1>
<div class="level1">
<pre class="file">1. ULINK project
    1.1 QTS can not boot completely (latency event issue) --&gt; Done.
    1.2 SAS template 24-50 implementation --&gt; In progress
      - APT for fetching data from SAS drive. --&gt; Done
      - Head data for ulink --&gt; In progress
      - Integration test --&gt; In progress
    1.3 Latency event issue analysis in booting phrase. --&gt; In progress
      - The latency time will be affected by io size.
    1.4 Enhancement
      - API for deleting all files.
      - file lock for read/write file. 
      - Confirm the location of statistic data file.

2. Systemtap study in QTS image.
  (http://spec.qnap.com.tw/projects/fault_injectiop/wiki/SystemTap_building_on_QTS)
  
3. Personal
  - vim environment set up.
  - 修改da_util</pre>

</div>
<!-- EDIT11 SECTION "20190617" [20638-21414] -->
<h1 class="sectionedit12" id="section20190610">20190610</h1>
<div class="level1">
<pre class="file">1. ULINK project 
    1.1 taskfile error counting for Marvell controller --&gt; Done.
        - Confirm the report value if the item is not supported by hardware controller.(0 is fine.)  
        - Summary spec and implementation details for item 16,22,23.
    1.2 Confirm SATA drive in expander --&gt; Done.
        --&gt; Cannot get ATA event.(Scsi event is fine.)
    1.3 Test for QTS-4.5.0 --&gt; Done.
    1.4 Issue analysis --&gt; QTS cannot boot completely --&gt; In progress
    
2. ToDo
    2.1 ULINK project 
        - SAS template 24-50 implementation.
        - Check hal latency event issue --&gt; QTS cannot boot completely.
        - API for deleting all binary files.
        - file lock for read/write binary file. 
        - Confirm the location of statistic data.
    2.2 Systemtap study in QTS image.
    
3. Personal
    3.1
</pre>

</div>
<!-- EDIT12 SECTION "20190610" [21415-22281] -->
<h1 class="sectionedit13" id="section20190603">20190603</h1>
<div class="level1">
<pre class="file">1. ULINK project implementation(item :16, 22, 23)
  1.1 ata link error count of ahci controller --&gt; Done.
  1.2 iotest(item 22) --&gt; Done.
    - da_util, da_util.sh and crontab content. 
    - Integrate with API of storage-man.
  1.3 Set drive latency value after booting.
  1.4 API for Burton. (Generate data buffer) --&gt; Done.
  1.5 Code test in QTS-4.4.x
  1.6 Trace code for Marvell controller -- In progress
  
2. ToDo
  1. ata cmd/link error count implementation for Marvell controller.
  2. file lock for drive statistic data.
  3. code test in QTS-4.5.0 version
  4. Summary ulink spec.
  5. Add a flag to distinguish action between delete/none-delete

Reference:
1. https://www.seagate.com/support/disc/manuals/sata/sata_im.pdf
  </pre>

</div>
<!-- EDIT13 SECTION "20190603" [22282-23060] -->
<h1 class="sectionedit14" id="section20190527">20190527</h1>
<div class="level1">
<pre class="file">1. ULINK project implementation(item :16, 22, 23)
  1.1 item 16:
    - ata command error count(including &quot;Drive not ready&quot;) --&gt; Done
    - ata link error count --&gt; It will be finished next week.

  1.2 item 22:
    - scsi command retry count --&gt; Done
    - IOPS and MBPS --&gt; Done
    - scsi command latency count --&gt; Done
      -- Add a parameter in scsi_device
      -- Control the value by sysfs. (qnap_param_latency)
  
  1.3 item 23:
    - scsi command error count --&gt; Done

2. ULINK project spec confirmation:
  2.1 Type of cell value --&gt; unsigned integer.
  2.2 Confirm long latency count.

3. ToDo:
  2.1 ULINK project
    - item 16 : ata link error count.
    - Marvell controller code trace: Error handle for ata command failure and ata link failure.
    - file lock when read/write counting file.
    - drive partition confirmation with Nike.
    - Integration with Burton.
   
  </pre>

</div>
<!-- EDIT14 SECTION "20190527" [23061-23991] -->
<h1 class="sectionedit15" id="section20190520">20190520</h1>
<div class="level1">
<pre class="file">[20190520]  
1. ULINK project (item :16, 22, 23)
  1. Code trace:
    1.1 Marvell controller
      --&gt; Need time to trace code for Marvell controller
    1.2 Error handle: ata command(template 16), ata link(template 16) and scsi command (template 22, 23).
    
  2. Spec confirm:
    2.1 Value type : Little Endian now.
    2.2 template revision : 100 (decimal) now.
    2.3 cell size : 16 bytes. (8 bytes reserved)
    
  3. Implementation and discussion:
    3.1 Issue event from Kernel to HAL by netlink. 
      - Add event code and structure in hal_event.h (Both in Kernel and hal)
    3.2 Simulated function for error state. 
    3.3 Name of file : disk_data_$serial_$temp.
    
2. Build Kernel, hal and DOM recovery:
  2.1 Build QTS kernel and hal, hal_util(hal_daemon).
    - Upgrade QTS from GUI. (韌體更新)
    - Upgrade QTS from script. (/etc/init.d/update.sh $image_name)
    - Replace Kernel:
      a. Mount partition-2 and partition-3 in DOM.
      b. Replace bzImage and bzImage.chsum
    - Build command:
      a. Build QTS image : time make CPU_N=-j8 BUILD_OPT=pure 2&gt;&amp;1 | tee log 
      b. Build Kernel : time make CPU_N=-j4 BUILD_OPT=pure BASE KERNEL 2&gt;&amp;1 | tee log
      c. Build hal_util: time make CPU_N=-j4 BUILD_OPT=pure NAS_UTILITY 2&gt;&amp;1 | tee log
        
  2.2 DOM recovery: 
      a. dd full image: dd if=//172.17.21.5/pub/NAS_FULL_IMAGE/xxx/xx.image of=/dev/sdx
      b. mkdir /mnt/update
      c. mount -t tmpfs none -o size=1G /mnt/update
      d. update release image from daily build: /etc/init.d/update.sh //172.17.21.5/pub/daily_build/xxx/xxx.img
      
3. ToDo
  3.1. Code trace:
    - Marvell controller code trace.
      --&gt; Error handle for ata command failure and ata link failure.
    
  3.2. Implementation:
    - file(binary format) for ULINK template.
    - Error distinguish and counting in HAL layer.
    - Integration with Burton&#039;s code structure.
    - IOPS Read/Write and Latency Read/Write

[20190513]   
1. ULINK project (item :16, 22, 23)
        1.1 Implementation detail discussion.
            --&gt; I will issue event from kernel space to user space , and the count will be accumulated in use space.)
        1.2 Netlink issue event test 
            --&gt; Send 100 messages continuously and no message is lost.
        1.3 Trace code : SATA error handle flow
            --&gt; Success and fail event : Be issued in SATA layer
            --&gt; Retry event : Be issued in SCSI layer.
        1.4  IOPS spec confirmation
            --&gt; fio test for different file-size (includs ssd and sata drive)
            --&gt; iodepth = 32, test duration=10, direct block io for SWAP partition of disk.
        1.5 Distinguish SATA drive in SCSI layer. (Use driver name currently.)
        1.6 SATA drive ready status study. (ATA_DRDY )
        1.7 Read/Write Operation : &quot;READ DMA EXT&quot;, &quot;READ FPDMA QUEUED&quot; and &quot;READ DMA&quot;
 
    2. ToDo
        2.1 A function for simulating error state in SATA driver.
        2.2 Implementation for issuing event to HAL, count recording (Success , Fail  and Retry event)
        2.3 IOPS data implementation and send data to ULINK website.
        2.4 marvell disk confirmation.  
  
[20190506]
    1. ULINK project 
        1.1 Confirm spec details (item :16, 22, 23)
        1.2 SATA code study for implementation
            a. Error handler of ATA command.
            b. The corresponding command/function for &quot;Unit Not Ready&quot;.
            c. Trace code flow of plug/unplug drive (How to check &quot;Unit Ready&quot;?)

    2. SCSI framework study
        2.1 request_fn --&gt; dispatch command --&gt; queuecommand --&gt; scsi_softirq_done

     ToDo:
        1. Confirm ULINK implementation details.
        2. SCSI framework, SATA code, SAS code study.

[20190426]
  [Multipath]
    1. Presentation for dm-multipath.
      1.1 Understanding the mechanism of no_path_retry and failover.
    2. Further study of dm-multipath:
      2.1 failback mechanism with plug/unplug SAS drive.
        --&gt; Control by multipathd (unrelated to Kernel module)
      2.2 ioctl command(SMART check) in dm-multipath
        --&gt; The ioctl command can be rerouted to real device.
      2.3 performance with dm-multipath (w/o dm-multipath) for SSD(SAS interface) and SAS dirve.  
        --&gt; https://docs.google.com/spreadsheets/d/1Ztgpf-RQa4JaMTDYEljTI-UcYEnVUFpS9LOcyzcZGbg/edit?usp=sharing
  [Todo]
    1. SCSI and SAS driver
    
[20190419]
  [Study : Multipath of device mapper]
      1. Device mapper framework architecture.
      2. bio-base mpath and request-base mpath
      3. Responsibility for multipathd(path check and failback) and dm-mpath(reroute and failover).
      4. &quot;alua is not supported&quot;
    
  [Todo]
      1. no_path_retry mechanism.
      2. Deep understanding for failover mechanism.
      3. Presentation for multipath of device mapper.
      4. Study for SAS protocol.
      
[20190412]
1. 開發環境建置與認識
        1. Account creation : 
            - Redmine, Bugzilla, git
            - vpn, gmail, skype, notes
        2. opengrok, wiki (personal)
        3. daily build server
        4. build server for NAS image.
            - Build image (Doc: Build QTS Firmware) and upgrade from NAS GUI.

    2. 工作流程認識
        - Redmine, Bugzilla, Excel for Model information (commit code to which model).
        - Doc : NASWare Development Environment

    3. Multipath study
        - Build mulipath 0.7.4 
        - SAS environment creation.
        - Learning behavior of multipath:
            - failover and multibus for path grouping.
            - round-robin for path selector.

ToDo:
    1. Multipath and Device mapper study:
    2. SAS driver study</pre>

</div>
<!-- EDIT15 SECTION "20190520" [23992-] -->